# 随机森林（Random Forest）_预测类_MCM-C/ICM-E/ICM-F

## 1. 模型基础信息

- 【模型类别】预测类
- 【题型适配】MCM-C，ICM-E，ICM-F
- 【任务类型】预测回归，分类分群（监督）
- 【数据特征】结构化表格数据；非线性；可处理部分缺失/噪声
- 【触发关键词】非线性、特征重要性、稳健、集成学习、树模型
- 【创新方向】验证与可解释，鲁棒/不确定性

## 2. 核心原理（AI 极简版）

用多棵随机采样与随机特征的决策树做集成，平均/投票降低方差，提高泛化能力，并可输出特征重要性。

## 3. 美赛适用场景

- **典型任务**：表格数据预测/分类；需要“重要因素排序”支撑结论。
- **数据条件**：样本量中等以上更稳；类别不平衡需处理。
- **Python 实现入口**：`sklearn.ensemble.RandomForestRegressor/Classifier`。

## 4. 美赛创新适配方案（可直接用）

1) 【可解释性】用特征重要性 + 置换重要性，并给出“关键因子”的管理含义。  
2) 【稳健性】对随机种子/采样做多次训练，给出性能均值与方差。  
3) 【与时间特征融合】把时间窗口统计量做成特征（rolling mean 等），RF 处理非线性映射。

## 5. 优缺点与避坑指南

- **优点**：鲁棒、少调参；对异常点不敏感；可解释性强于神经网络。
- **缺点**：精度可能不如 XGBoost；外推能力有限。
- **避坑**：不要只报训练集效果；必须做交叉验证；外推预测要谨慎解释。

## 6. 替代模型推荐

- XGBoost/LightGBM：追求更高精度与更强特征表达时。
- 线性/正则回归：强解释且关系近线性时。
- GPR：需要预测区间与不确定性时。

