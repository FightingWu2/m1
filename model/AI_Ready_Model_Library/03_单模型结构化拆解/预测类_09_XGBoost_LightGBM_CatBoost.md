# XGBoost / LightGBM / CatBoost_预测类_MCM-C/ICM-E/ICM-F

## 1. 模型基础信息

- 【模型类别】预测类
- 【题型适配】MCM-C，ICM-E，ICM-F
- 【任务类型】预测回归，分类
- 【数据特征】结构化表格数据；高维；非线性；缺失值/异常值较常见
- 【触发关键词】集成学习、Boosting、特征重要性、SOTA、表格数据、非线性
- 【创新方向】验证与可解释，参数改进

## 2. 核心原理（AI 极简版）

用梯度提升树逐步拟合残差，形成强模型；对结构化数据常优于传统回归与随机森林，并可输出特征重要性。

## 3. 美赛适用场景

- **典型任务**：高精度预测与关键因子解释；MCM-C/ICM-E/F 的“数据洞察主力”。
- **数据条件**：需要合理特征工程与交叉验证；避免数据泄漏。
- **Python 实现入口**：`xgboost.XGBRegressor/Classifier` 或 `lightgbm.LGBMRegressor/Classifier`。

## 4. 美赛创新适配方案（可直接用）

1) 【超参搜索】`GridSearchCV` 或 Bayesian Optimization（若不做也至少给手动搜索范围）。  
2) 【可解释性】输出 feature importance + SHAP（若环境允许），并把“关键因素→建议”写成评审读得懂的话。  
3) 【不确定性】用分位数回归/Bootstrap 得到预测区间，避免只给点预测。

## 5. 优缺点与避坑指南

- **优点**：精度强；对缺失/非线性友好；解释工具链成熟。
- **缺点**：调参空间大；容易数据泄漏导致“虚高分”。
- **避坑**：时间序列不能随机打乱做 CV；必须做严格的训练/验证切分；特征工程要写清来源时间点。

## 6. 替代模型推荐

- 随机森林：更少调参、稳健基线。
- 线性/正则回归：更强解释与可推断时。
- LSTM/GRU：长序列时序数据、强非线性时更合适。

